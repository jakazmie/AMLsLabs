{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and Setup\n",
    "This series of hands-on labs demonstrates how to orchestrate an end-to-end machine learning worklow using Azure Machine Learning service. \n",
    "\n",
    "All labs are based on the same scenario.\n",
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "You will train a custom image classification model to automatically classify the type of land shown in aerial images of 224-meter x 224-meter plots. Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery. The images used in this lab are based off of imagery from the U.S. National Land Cover Database. U.S. National Land Cover Database defines six primary classes of land use: *Developed*, *Barren*, *Forested*, *Grassland*, *Shrub*, *Cultivated*. Example images from each land use class are shown here:\n",
    "\n",
    "Developed | Cultivated | Barren\n",
    "--------- | ------ | ----------\n",
    "![Developed](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/developed1.png) | ![Cultivated](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/cultivated1.png) | ![Barren](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/barren1.png)\n",
    "\n",
    "Forested | Grassland | Shrub\n",
    "---------| ----------| -----\n",
    "![Forested](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/forest1.png) | ![Grassland](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/grassland1.png) | ![Shrub](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/shrub1.png)\n",
    "\n",
    "After an initial experimentation with simple classification models, you shall employ a machine learning technique called transfer learning. Transfer learning is one of the fastest (code and run-time-wise) ways to start using deep learning. It allows for the reuse of knowledge gained while solving one problem to a different but related problem. For example, knowledge gained while learning to recognize landmarks and landscapes could apply when trying to recognize aerial land plots. Transfer Learning makes it feasible to train very effective ML models on relatively small training data sets.\n",
    "\n",
    "Although the primary goal of this lab is to understand how to use Azure ML to orchestrate machine learning workflows rather then to dive into Deep Learning techniques, ask the instructor if you want to better understand the approach utilized in the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labs\n",
    "\n",
    "The labs cover a number of techniques applied when training and deploying nontrivial machine learning models.\n",
    "\n",
    "- Experimentation in a local development environment.\n",
    "\n",
    "- Tracking performance measures, logs and other artifacts generated during training.\n",
    "\n",
    "- Executing computationally expensive workloads on Azure AI infrastructure\n",
    "\n",
    "- Feature extraction with pretrained Deep Neural Networks. \n",
    "\n",
    "- Model selection with `Automated ML`.\n",
    "\n",
    "- Scale-out hyper-parameter tuning with `Hyperdrive`.\n",
    "\n",
    "- Model tracking and model operationalization\n",
    "\n",
    "\n",
    "Each lab runs as a Jupyter notebook:\n",
    "\n",
    "* Lab 1 - Experimenation in a local environment\n",
    "* Lab 2 - Feature extraction using a remote VM \n",
    "* Lab 3 - Model selection with Automated ML\n",
    "* Lab 4 - Model operationalization in ACI\n",
    "* Lab 5 - Scale-out hyper-parameter tuning with Hyperdrive \n",
    "* Lab 6 - Model operationalization in FPGA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is Azure Machine Learning service?\n",
    "\n",
    "Azure Machine Learning service is a cloud service that you can use to develop and deploy machine learning models. Using Azure Machine Learning service, you can track your models as you build, train, deploy, and manage them, all at the broad scale that the cloud provides.\n",
    "\n",
    "Azure Machine Learning service fully supports open-source technologies, so you can use tens of thousands of open-source Python packages with machine learning components such as TensorFlow, PyTorch, MXNet and scikit-learn. \n",
    "\n",
    "In this lab, you are going to use `scikit-learn` and `tensorflow.keras`.\n",
    "\n",
    "Azure Machine Learning service helps you orchestrate machine learning workflows using the architecture depicted on the below diagram.\n",
    "\n",
    "![AML workflow](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)\n",
    "\n",
    "\n",
    "1. Data preparation and model training logic are coded as Python scripts utilizing any of the hundreds of supported libraries and frameworks. The scripts can be instrumented with AML API calls to help with capturing and managing records of training runs, such as performance measures, logs, serialized models, etc.\n",
    "\n",
    "2. The scripts can execute in your local environment or on a remote Compute Target. You would usually do code development and debugging in your local environment using a small development dataset and train on a full training dataset on a remote Compute Target. The primary remote targets are Azure VMs and Azure Batch AI clusters. The training and validation data accessed by Compute Targets is stored in AML Datastores that are backed up by Azure Blob Storage or Azure Data Lake.\n",
    "\n",
    "3. As you run training iterations - a.k.a. runs - run records are stored in Azure ML service Experiment. You can query the Experiment's content using Python APIs or browser through it using Azure Portal.\n",
    "\n",
    "4. When your model is ready for deployment you register it in Model Registry. Model Registry maintains versions of the model including the model's serialized files and metadata.\n",
    "\n",
    "5. Depending on you deployment target, AML will create an optimized docker image and store it in private Azure Container Registry. The image includes the model, the scoring file to invoke the model, and all required runtime dependencies.\n",
    "\n",
    "6. The image can be deployed to any of the supported targets including Azure Container Instance, Azure Kubernetes Services, or Azure IoT Edge. \n",
    "\n",
    "\n",
    "All Azure ML components are managed within a top level container - Azure Machine Learning Workspace. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.74\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Azure Machine Learning Workspace\n",
    "\n",
    "Before you can start the labs, you need to provision Azure Machine Learning Workspace.  You can create AML Workspace using AML Python SDK, AML CLI, or Azure Portal. We will use Python SDK.\n",
    "\n",
    "Replace the placeholders in the code below with your values for Azure subscription ID, a workspace name, a resource group name, and a region. *Select the region that gives you access to **Standard_NC6** virtual machines. Check with you subscription administrator.* When you execute the cell you will be asked to log in to Azure. Follow the printed instructions and use your Azure credentials to complete authentication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id ='<your subscription id>'\n",
    "resource_group ='<your resource group>'\n",
    "workspace_name = '<your workspace name>'\n",
    "workspace_region = '<your region>'\n",
    "  \n",
    "# Try to create a workspace. If the workspace already exists retrieve and store configuration\n",
    "try:\n",
    "   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "\n",
    "   print('Workspace configuration succeeded. You are all set!')\n",
    "except:\n",
    "   print('Workspace not found. Creating...')\n",
    "   ws = Workspace.create(name = workspace_name,\n",
    "                subscription_id = subscription_id,\n",
    "                resource_group = resource_group, \n",
    "                location = workspace_region,\n",
    "                create_resource_group = True,\n",
    "                exist_ok = True)\n",
    "\n",
    "ws.get_details()\n",
    "ws.write_config('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "Your AML Workspace is ready and the configuration has been written to a json config file. You can now proceed to the first part of the lab - experimenting in a local environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
