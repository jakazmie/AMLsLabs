{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Training and tuning FCNN classifier\n",
    "\n",
    "\n",
    "In this lab we will attempt to further improve our image classifier by training a simple fully connected neural network using using the bottleneck features.\n",
    "\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/TLArch.png)\n",
    "\n",
    "\n",
    "We will first demonstrate who to run the training script locally to facilitate development and debugging.\n",
    "\n",
    "After that will use AML feature called `Hyperdrive` to fine tune hyperparameters of our neural network. `Hyperdrive` will utilize Azure Batch AI GPU cluster to run and evaluate concurrent training jobs. After the model is fine tuned, the best version will be registered in AML Model Registry.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.74\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML Workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML Experiment\n",
    "\n",
    "To track training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'aerial-train-fcnn'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training script\n",
    "\n",
    "In the training script, we use Tensorflow.Keras to define and train a simple fully connected neural network.\n",
    "\n",
    "The network has one hidden layer. The input to the network is a vector of 2048 floating point numbers - the bottleneck features created in Lab 2. The output layer consists of 6 units - representing six land type classes. To control overfitting the network uses a Dropout layer between the hidden layer and the output layer and L1 and L2 regularization in the output layer.\n",
    "\n",
    "The number of units in the hidden layer, L1 and L2 values, and batch size are all tuneable hyperparameters. The Dropout ratio is fixed at 0.5.\n",
    "\n",
    "Since the bottleneck feature files are small (as compared to original image datasets) they can be loaded into memory all at once.\n",
    "\n",
    "The trained model will be saved into the ./outputs folder. This is one of the special folders in AML. The other one is the ./logs folder. The content in these folders is automatically uploaded to the run history.\n",
    "\n",
    "The script uses AML Run object to track two performane measures: training accuracy and validation accuracy. The metrics are captured at the end of each epoch.\n",
    "\n",
    "\n",
    "### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "script_name = 'train.py'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Jupyter `%%writefile` magic to write the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Create custom callback to track accuracy measures in AML Experiment\n",
    "class RunCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.run.log(name=\"training_acc\", value=float(logs.get('acc')))\n",
    "        self.run.log(name=\"validation_acc\", value=float(logs.get('val_acc')))\n",
    "\n",
    "\n",
    "# Define network\n",
    "def fcn_classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training regime\n",
    "def train_evaluate(run):\n",
    "   \n",
    "    print(\"Loading bottleneck features\")\n",
    "    train_file_name = os.path.join(FLAGS.data_folder, FLAGS.train_file_name)\n",
    "    \n",
    "    # Load bottleneck training features and labels\n",
    "    with h5py.File(train_file_name, \"r\") as hfile:\n",
    "        features = np.array(hfile.get('features'))\n",
    "        labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Split the data into training and validation partitions   \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "        \n",
    "    # Convert labels into one-hot encoded format\n",
    "    y_train = to_categorical(y_train, num_classes=6)\n",
    "    y_validation = to_categorical(y_validation, num_classes=6)\n",
    "    \n",
    "    # Create a network\n",
    "    model = fcn_classifier(input_shape=(2048,), units=FLAGS.units, l1=FLAGS.l1, l2=FLAGS.l2)\n",
    "    \n",
    "    # Create AML tracking callback\n",
    "    run_callback = RunCallback(run)\n",
    "    \n",
    "    # Start training\n",
    "    print(\"Starting training\")\n",
    "    model.fit(X_train, y_train,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          epochs=FLAGS.epochs,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_validation, y_validation),\n",
    "          callbacks=[run_callback])\n",
    "          \n",
    "    # Save the trained model to outputs which is a standard folder expected by AML\n",
    "    print(\"Training completed.\")\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    model_file = os.path.join('outputs', 'aerial_fcnn_classifier.hd5')\n",
    "    print(\"Saving model to: {0}\".format(model_file))\n",
    "    model.save(model_file)\n",
    "    \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_float('l1', 0.01, \"l1 regularization\")\n",
    "tf.app.flags.DEFINE_float('l2', 0.01, \"l2 regularization\")\n",
    "tf.app.flags.DEFINE_string('data_folder', './bottleneck', \"Folder with bottleneck features and labels\")\n",
    "tf.app.flags.DEFINE_string('train_file_name', 'aerial_bottleneck_resnet50.h5', \"Training file name\")\n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    # get hold of the current run\n",
    "    run = Run.get_submitted_run()\n",
    "    train_evaluate(run)\n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download bottleneck features \n",
    "\n",
    "The bottleneck features file has been uploaded to the default datastore in Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'bottleneck_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerial_bottleneck_resnet50_brainwave.h5\r\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.download(target_path='/tmp', prefix=data_folder, overwrite=True)\n",
    "!ls /tmp/bottleneck_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Run environment\n",
    "We will use a user-managed run, which means we assume that all the necessary packages are already available in the Python environment selected to run the script. In our case this is true, as we pre-installed all the dependencies during the lab setup. Alternatively, you can execute a local run in system-managed environment. In that case AML would build a new conda environment and execute the script in it.\n",
    "\n",
    "*Make sure to modify the **interpreter_path** property to point to your Python environment. On DSVM this path is `/anaconda/envs/py36/bin/python`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = '/anaconda/envs/py36/bin/python'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the script. \n",
    "Note that we need to supply an absolute path to the folder with training  images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-train-fcnn</td><td>aerial-train-fcnn_1542738310_5163c245</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-train-fcnn/runs/aerial-train-fcnn_1542738310_5163c245\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-train-fcnn,\n",
       "Id: aerial-train-fcnn_1542738310_5163c245,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=script_folder,\n",
    "    script=script_name,\n",
    "    run_config=run_config,\n",
    "    arguments=['--data_folder', '/tmp/bottleneck_features',\n",
    "               '--train_file_name', 'aerial_bottleneck_resnet50_brainwave.h5',\n",
    "               '--l1', 0.001,\n",
    "               '--l2', 0.001,\n",
    "               '--units', 512,\n",
    "               '--epochs', 40])\n",
    "\n",
    "tags = {\"Compute target\": \"Local\"}\n",
    "run = exp.submit(src, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ec5154e82448f3a3f29d27dc00e4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the job completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune the network with `Hyperdrive`\n",
    "\n",
    "If you analyze the *training_acc* and *validation_acc* charts you will notice that *training_acc* continues to climb while *validation_acc* reaches a plateua and may even start degrading. This is an indication of overfitting. In the next part we will tune hyper-parameters of the model to achieve better and more consistent performance.\n",
    "\n",
    "We will use AML Hyperdrive and Azure Batch AI GPU cluster to run concurrent hyperparameter tuning jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create remote compute cluster\n",
    "\n",
    "We will use Azure Batch AI GPU cluster to run  hyper parameter tuning.\n",
    "\n",
    "The cluster is set up for autoscaling. It will start with a single node and can scale to up to 4 nodes. The nodes are NC6 VMs with Tesla K80 GPU.\n",
    "\n",
    "**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpudsvm VirtualMachine\n",
      "batchaicls BatchAI\n",
      "batchaigpucls BatchAI\n",
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "batchai_cluster_name = \"batchaigpucls\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "for ct_name, ct in ws.compute_targets.items():\n",
    "    print(ct.name, ct.type)\n",
    "    if (ct.name == batchai_cluster_name and ct.type == 'BatchAI'):\n",
    "        found = True\n",
    "        print('Found existing compute target.')\n",
    "        bai_compute_target = ct\n",
    "        break\n",
    "        \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\", \n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 1, \n",
    "                                                                cluster_max_nodes = 4)\n",
    "\n",
    "    # Create the cluster.\n",
    "    bai_compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "    bai_compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during Lab 2. We will mount the store on the nodes of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default datastore for training data: \n",
      "workspacefilestore AzureFile jkamllab3650394639 azureml-filestore-bc740c20-4b07-49e7-92ba-c5bf27a7cb86\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a test run on a single node of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck_features').as_download(),\n",
    "    '--training_file_name': 'aerial_bottleneck_resnet50_brainwave.h5',\n",
    "    '--l1': 0.001,\n",
    "    '--l2': 0.001,\n",
    "    '--units': 512,\n",
    "    '--epochs': 10\n",
    "}\n",
    "\n",
    "\n",
    "pip_packages = ['h5py','pillow', 'scikit-learn', 'tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=bai_compute_target,\n",
    "                entry_script=script_name,\n",
    "                pip_packages=pip_packages,\n",
    "                use_gpu=True,\n",
    "                node_count=1,\n",
    "                process_count_per_node=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-train-fcnn</td><td>aerial-train-fcnn_1542743173388</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-train-fcnn/runs/aerial-train-fcnn_1542743173388\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-train-fcnn,\n",
       "Id: aerial-train-fcnn_1542743173388,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {\"Compute target\": \"BAI\", \"Run Type\": \"Test drive\"}\n",
    "run = exp.submit(est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0403f0c76b43d79623541099661b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: aerial-train-fcnn_1542733666050\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "Logging into Docker registry: jkamllab6512356786.azurecr.io\n",
      "Login Succeeded\n",
      "Docker login(s) took 5.332667112350464 seconds\n",
      "Building image with name jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683\n",
      "Sending build context to Docker daemon  123.4kB\n",
      "\n",
      "Step 1/13 : FROM mcr.microsoft.com/azureml/base-gpu:0.1.4\n",
      " ---> 663fe1ed3f82\n",
      "Step 2/13 : USER root\n",
      " ---> Running in 86da07aae463\n",
      " ---> 7dfd465015cb\n",
      "Removing intermediate container 86da07aae463\n",
      "Step 3/13 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 6fbc908a8d92\n",
      " ---> bdc2ee33f931\n",
      "Removing intermediate container 6fbc908a8d92\n",
      "Step 4/13 : WORKDIR /\n",
      " ---> aa6555be3ae5\n",
      "Removing intermediate container c8b4e43f0480\n",
      "Step 5/13 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> e4bc76cc2ec4\n",
      "Step 6/13 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.0; then conda install conda==4.4.11; fi\n",
      " ---> Running in 2929e78ba73e\n",
      " ---> feb89b7a47ac\n",
      "Removing intermediate container 2929e78ba73e\n",
      "Step 7/13 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n",
      " ---> 9c368fada3b9\n",
      "Step 8/13 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70 -f azureml-setup/mutated_conda_dependencies.yml && ldconfig\n",
      " ---> Running in 1a5153e7e061\n",
      "Solving environment: ...working... done\n",
      "\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 920 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #########1 |  92% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #######9   |  80% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #######7   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #########9 | 100% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-18.1             | 1.8 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2018 | 124 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2018 | 124 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-8.2.0      | 7.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########6 |  97% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########3  |  83% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #6         |  17% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ###8       |  39% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ######2    |  62% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######6   |  76% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########6  |  87% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########4 |  94% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.32.3         | 35 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.32.3         | 35 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2p       | 3.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #########3 |  93% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2018.10.15   | 139 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2018.10.15   | 139 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 101 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 101 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-40.6.2    | 604 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########4  |  84% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults (from -r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/2f/fdde2a606f4a8f0bbd341edf20f0a689001b1c5785fb4dbe771a9913dbc4/azureml_defaults-0.1.80-py2.py3-none-any.whl\n",
      "Collecting h5py (from -r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "Collecting pillow (from -r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "Collecting scikit-learn (from -r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/b2/05be9b6da9ae4a4c54f537be22e95833f722742a02b1e355fdc09363877c/scikit_learn-0.20.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
      "Collecting tensorflow-gpu (from -r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/55/7e/bec4d62e9dc95e828922c6cec38acd9461af8abe749f7c9def25ec4b2fdb/tensorflow_gpu-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (281.7MB)\n",
      "Collecting applicationinsights>=0.11.0 (from azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/c8/7848a0dd85158930b859eb8be1e38fc76a91f0a040d491723ebb356d7358/applicationinsights-0.11.7-py2.py3-none-any.whl (56kB)\n",
      "Collecting azureml-core==0.1.80.* (from azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/a3/8789ed59f632e027cc2ac9301cd78e36b6b0846c44722e96b340418f1468/azureml_core-0.1.80-py2.py3-none-any.whl (805kB)\n",
      "Collecting numpy>=1.7 (from h5py->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
      "Collecting six (from h5py->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting scipy>=0.13.3 (from scikit-learn->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting absl-py>=0.1.6 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/63/f505d2d4c21db849cf80bad517f0065a30be6b006b0a5637f1b95584a305/absl-py-0.6.1.tar.gz (94kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/d0/65fe48383146199f16dbd5999ef226b87bce63ad5cd73c840cf722637969/tensorboard-1.12.0-py3-none-any.whl (3.0MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/4f/e9e84e4600c43cae7ce58489c6e73ff4c864557bc4d4d0f0029c79e07f31/grpcio-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (9.7MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5)) (0.32.3)\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting msrest>=0.5.1 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/40/70e545b7a5b0509273c6fe981118fb64e389fe013504b1c22a24fec4d1d9/msrest-0.6.2-py2.py3-none-any.whl (81kB)\n",
      "Collecting requests>=2.19.1 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl (57kB)\n",
      "Collecting pathspec (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
      "Collecting PyJWT (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/d1/3378cc8184a6524dc92993090ee8b4c03847c567e298305d6cf86987e005/PyJWT-1.6.4-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/d9/496b29857a252bc3fcc4bbda069c0eb64b537c8e8f7e342abb4053ba920f/azure_mgmt_storage-3.1.0-py2.py3-none-any.whl (696kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/18/1583e40c38ff8572c42e56ce17b95357a9ebb91375cfbd7aad63cac9a32e/cryptography-2.4.1-cp34-abi3-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting azure-storage-blob>=1.1.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/b7/9b20c39bf411e896d110d01f2551e6e7b397fde6eb06b07293fe29705d13/azure_storage_blob-1.4.0-py2.py3-none-any.whl (75kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d1/e8887811e8e5ab336e77db7cfb9f451bdae69a8ed97f53cc2cd11fdcac8f/azure_mgmt_containerregistry-2.4.0-py2.py3-none-any.whl (482kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/91/cad6fb2eb9ad106c8d5bd45514af2772c956e921f57b85db6bd0919923e7/azure_mgmt_authorization-0.51.0-py2.py3-none-any.whl (111kB)\n",
      "Collecting azure-cli-core>=2.0.38 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/18/fa/4adcb8d2a7683ba972eb2b56d68f21cd0d5b43222c368c5ee6bc38cf2e4d/azure_cli_core-2.0.50-py2.py3-none-any.whl (107kB)\n",
      "Collecting azure-storage-common>=1.1.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/84/025ac436a6a1d5516d1a67887d7122b3b2ea04ba6b2d2c46fe949accb62b/azure_storage_common-1.4.0-py2.py3-none-any.whl (46kB)\n",
      "Collecting urllib3<1.24,>=1.23 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl (133kB)\n",
      "Collecting python-dateutil>=2.7.3 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl (225kB)\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/84/b4558e3f469c67497a2a5eaeb05321f91b1ee2d1205992a33f001d9c4bf9/azure_graphrbac-0.52.0-py2.py3-none-any.whl (108kB)\n",
      "Collecting ruamel.yaml<=0.15.51,>=0.15.35 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/7f/9bb3ba89ceab600c4a0ea75d638ea945215ca3458ac6528e0e39fa3254e4/ruamel.yaml-0.15.51-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
      "Collecting docker (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/76/b8091dc6d9db038af62ae88f228da656a84632cf5d7a84dcf54c613d3fd0/docker-3.5.1-py2.py3-none-any.whl (126kB)\n",
      "Collecting azure-cli-profile>=2.0.26 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/d3/fdc722a1b61857250a76027d6d73a50182c6d85132ddd65600a8993574ce/azure_cli_profile-2.1.2-py2.py3-none-any.whl\n",
      "Collecting backports.tempfile (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111kB)\n",
      "Collecting jsonpickle (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ce/97404d5aeb58e6155c216825c81b50f6eca8a5345c582317ae48391878f8/jsonpickle-1.0-py2.py3-none-any.whl\n",
      "Collecting pytz (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/26/c0cb69dfac2e5b7125db034045b8bcf937cf1e8d3df2009a87c33d0959f5/azure_mgmt_resource-2.0.0-py2.py3-none-any.whl (698kB)\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/62/6e/c41d6e2db39f4c6b819cea5b47c36c0fa0e7a931cd39b4c5f19713d28fd1/msrestazure-0.5.1-py2.py3-none-any.whl\n",
      "Collecting ndg-httpsclient (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting azure-storage-nspkg>=3.0.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/f6/054ace7b01c6c21b3b95a83c3997f7d6539d939a2c08c4f27f779128a030/azure_storage_nspkg-3.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/d3/055ce7ad06459a415ff9ca210e04c6cbb51bd6564815b7c8ac34bf5a1c39/azure_common-1.1.16-py2.py3-none-any.whl\n",
      "Collecting SecretStorage<3.0.0 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/a5/0830cfe34a4cfd0d1c3c8b614ede1edb2aaf999091ac8548dd19cb352e79/SecretStorage-2.3.1.tar.gz\n",
      "Collecting contextlib2 (from azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 5)) (40.6.2)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1)) (2018.10.15)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting idna<2.8,>=2.5 (from requests>=2.19.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
      "Collecting cffi!=1.11.3,>=1.7 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "Collecting knack==0.4.5 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/02/89/1ea05831b95d6bdc8880acdd0304a915156eb5f94aeab0fd36649a940c45/knack-0.4.5-py2.py3-none-any.whl (49kB)\n",
      "Collecting pyopenssl>=17.1.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting humanfriendly>=4.7 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl (72kB)\n",
      "Collecting adal>=1.2.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/2f/14882b8dae0977e85577abde3065c141fb94dbb242adfb80e21797e4f7c9/adal-1.2.0-py2.py3-none-any.whl (52kB)\n",
      "Collecting tabulate<=0.8.2,>=0.7.7 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
      "Collecting pygments (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl (841kB)\n",
      "Collecting jmespath (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting antlr4-python3-runtime; python_version >= \"3.0\" (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/96/aba01b2948ec67f237cd387c022820835ae0d8db5cab4bd404b351660b5e/antlr4-python3-runtime-4.7.1.tar.gz (111kB)\n",
      "Collecting azure-cli-nspkg>=2.0.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/85/601ef6484bf7a722daa76a4383c4ccfd4980b74ed6c2895392f53ed210d5/azure_cli_nspkg-3.0.3-py2.py3-none-any.whl\n",
      "Collecting pyyaml~=3.13 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting argcomplete>=1.8.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/31/88/ba8d8684a8a27749250c66ff7c2b408fdbc29b50da61200338ff9b2607bf/argcomplete-1.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pip in /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1)) (18.1)\n",
      "Collecting colorama>=0.3.9 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/93/6e8289231675d561d476d656c2ee3a868c1cca207e16c118d4503b25e2bf/colorama-0.4.0-py2.py3-none-any.whl\n",
      "Collecting azure-cli-telemetry (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/4c/da5ebe9300ecdc850031372f81229383c46a70e83dee8e77f58aa6fd0546/azure_cli_telemetry-1.0.0-py2.py3-none-any.whl\n",
      "Collecting paramiko>=2.0.8 (from azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting docker-pycreds>=0.3.0 (from docker->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/bf/7e70aeebc40407fbdb96fa9f79fc8e4722ea889a99378303e3bcc73f4ab5/docker_pycreds-0.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-cli-command-modules-nspkg>=2.0.0 (from azure-cli-profile>=2.0.26->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/c9/cdeeeabc550848e2a07caa66cba28aa057d23b6feaa824ceafd32c3f2226/azure_cli_command_modules_nspkg-2.0.2-py2.py3-none-any.whl\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-keyvault>=0.40.0->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/a1/7790cc85db38daa874f6a2e6308131b9953feb1367f2ae2d1123bb93a9f5/pyasn1-0.4.4-py2.py3-none-any.whl (72kB)\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-storage-nspkg>=3.0.0->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl (121kB)\n",
      "Collecting pycparser (from cffi!=1.11.3,>=1.7->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Collecting portalocker==1.2.1 (from azure-cli-telemetry->azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/57/41/05e79e5516db1cc0c967b3202388cde729f871c871b0a07bf24ff11adfcf/portalocker-1.2.1-py2.py3-none-any.whl\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/09/905ec939994e2c49dcffff72f823802557f166b3815ea54c1db3671eed42/bcrypt-3.1.4-cp36-cp36m-manylinux1_x86_64.whl (54kB)\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.80.*->azureml-defaults->-r /azureml-setup/condaenv.ofqmv17j.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
      "Building wheels for collected packages: gast, absl-py, termcolor, pathspec, SecretStorage, tabulate, antlr4-python3-runtime, pyyaml, pycparser\n",
      "  Running setup.py bdist_wheel for gast: started\n",
      "  Running setup.py bdist_wheel for gast: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for absl-py: started\n",
      "  Running setup.py bdist_wheel for absl-py: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/ea/5e/e36e1b8739e78cd2eba0a08fdc602c2b16a4b263912af8cb64\n",
      "  Running setup.py bdist_wheel for termcolor: started\n",
      "  Running setup.py bdist_wheel for termcolor: finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for pathspec: started\n",
      "  Running setup.py bdist_wheel for pathspec: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
      "  Running setup.py bdist_wheel for SecretStorage: started\n",
      "  Running setup.py bdist_wheel for SecretStorage: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/5b/1b/be8c8a830a0243af85b2946a0aece2c6743d7f7f946977ed67\n",
      "  Running setup.py bdist_wheel for tabulate: started\n",
      "  Running setup.py bdist_wheel for tabulate: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: started\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/f6/18/ad300e691236a3408a99edc750484b56e8d6b11b2c38eacb10\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Running setup.py bdist_wheel for pycparser: started\n",
      "  Running setup.py bdist_wheel for pycparser: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "Successfully built gast absl-py termcolor pathspec SecretStorage tabulate antlr4-python3-runtime pyyaml pycparser\n",
      "\u001b[91mazure-cli-core 2.0.50 has requirement wheel==0.30.0, but you'll have wheel 0.32.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: applicationinsights, oauthlib, chardet, urllib3, idna, requests, requests-oauthlib, six, isodate, msrest, pathspec, PyJWT, azure-common, python-dateutil, pycparser, cffi, asn1crypto, cryptography, adal, msrestazure, azure-mgmt-storage, azure-storage-common, azure-storage-blob, azure-mgmt-containerregistry, azure-mgmt-authorization, colorama, pygments, jmespath, pyyaml, argcomplete, tabulate, knack, pyopenssl, humanfriendly, antlr4-python3-runtime, azure-nspkg, azure-cli-nspkg, azure-mgmt-nspkg, azure-mgmt-resource, portalocker, azure-cli-telemetry, bcrypt, pynacl, pyasn1, paramiko, azure-cli-core, azure-graphrbac, ruamel.yaml, websocket-client, docker-pycreds, docker, azure-cli-command-modules-nspkg, azure-cli-profile, backports.weakref, backports.tempfile, azure-mgmt-keyvault, jsonpickle, pytz, ndg-httpsclient, azure-storage-nspkg, SecretStorage, contextlib2, azureml-core, azureml-defaults, numpy, h5py, pillow, scipy, scikit-learn, gast, absl-py, keras-preprocessing, markdown, grpcio, werkzeug, protobuf, tensorboard, termcolor, keras-applications, astor, tensorflow-gpu\n",
      "Successfully installed PyJWT-1.6.4 SecretStorage-2.3.1 absl-py-0.6.1 adal-1.2.0 antlr4-python3-runtime-4.7.1 applicationinsights-0.11.7 argcomplete-1.9.4 asn1crypto-0.24.0 astor-0.7.1 azure-cli-command-modules-nspkg-2.0.2 azure-cli-core-2.0.50 azure-cli-nspkg-3.0.3 azure-cli-profile-2.1.2 azure-cli-telemetry-1.0.0 azure-common-1.1.16 azure-graphrbac-0.52.0 azure-mgmt-authorization-0.51.0 azure-mgmt-containerregistry-2.4.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.0.0 azure-mgmt-storage-3.1.0 azure-nspkg-3.0.2 azure-storage-blob-1.4.0 azure-storage-common-1.4.0 azure-storage-nspkg-3.1.0 azureml-core-0.1.80 azureml-defaults-0.1.80 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.4 cffi-1.11.5 chardet-3.0.4 colorama-0.4.0 contextlib2-0.5.5 cryptography-2.4.1 docker-3.5.1 docker-pycreds-0.3.0 gast-0.2.0 grpcio-1.16.1 h5py-2.8.0 humanfriendly-4.17 idna-2.7 isodate-0.6.0 jmespath-0.9.3 jsonpickle-1.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 knack-0.4.5 markdown-3.0.1 msrest-0.6.2 msrestazure-0.5.1 ndg-httpsclient-0.5.1 numpy-1.15.4 oauthlib-2.1.0 paramiko-2.4.2 pathspec-0.5.9 pillow-5.3.0 portalocker-1.2.1 protobuf-3.6.1 pyasn1-0.4.4 pycparser-2.19 pygments-2.2.0 pynacl-1.3.0 pyopenssl-18.0.0 python-dateutil-2.7.5 pytz-2018.7 pyyaml-3.13 requests-2.20.1 requests-oauthlib-1.0.0 ruamel.yaml-0.15.51 scikit-learn-0.20.0 scipy-1.1.0 six-1.11.0 tabulate-0.8.2 tensorboard-1.12.0 tensorflow-gpu-1.12.0 termcolor-1.1.0 urllib3-1.23 websocket-client-0.54.0 werkzeug-0.14.1\n",
      "#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\u001b[91m\n",
      "\u001b[0m ---> 8a3b33d7b3f9\n",
      "Removing intermediate container 1a5153e7e061\n",
      "Step 9/13 : ENV PATH /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/bin:$PATH\n",
      " ---> Running in 4321214a44bd\n",
      " ---> e44ce3d1db7a\n",
      "Removing intermediate container 4321214a44bd\n",
      "Step 10/13 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in f1ea5e27f32d\n",
      " ---> 9197a58ed829\n",
      "Removing intermediate container f1ea5e27f32d\n",
      "Step 11/13 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> 439b3b697a6e\n",
      "Step 12/13 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" \"--conf\" \"spark.app.name=Azure ML Experiment\" \"--conf\" \"spark.yarn.maxAppAttempts=1\" \"--driver-java-options\" \"-Dlog4j.configuration=file:./azureml-setup/log4j.properties\" \"--conf\" \"spark.eventLog.enabled=true\" \"--conf\" \"spark.eventLog.dir=./azureml-logs\" /azureml-setup/spark_cache.py'; fi\n",
      " ---> Running in b81496411452\n",
      " ---> 15eb5a7537e3\n",
      "Removing intermediate container b81496411452\n",
      "Step 13/13 : CMD bash\n",
      " ---> Running in 6e64c631f2f2\n",
      " ---> d1eba71d8159\n",
      "Removing intermediate container 6e64c631f2f2\n",
      "Successfully built d1eba71d8159\n",
      "Successfully tagged jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683:latest\n",
      "Removing any dangling images\n",
      "Docker build took 281.05839705467224 seconds\n",
      "Logging into acr jkamllab6512356786.azurecr.io to do docker push\n",
      "Login Succeeded\n",
      "Pushing image azureml/azureml_f279bc0a042728bf2096729c6942b683 to acr jkamllab6512356786.azurecr.io\n",
      "The push refers to a repository [jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683]\n",
      "f275626cba41: Preparing\n",
      "ca9b91ed4222: Preparing\n",
      "d4618962ee78: Preparing\n",
      "9949025bc22c: Preparing\n",
      "d43cd90ec4b4: Preparing\n",
      "0d64a93a303a: Preparing\n",
      "f41953166959: Preparing\n",
      "392a009de2b3: Preparing\n",
      "1db0da3b3d01: Preparing\n",
      "e46e9e8b1cbf: Preparing\n",
      "75b79e19929c: Preparing\n",
      "4775b2f378bb: Preparing\n",
      "883eafdbe580: Preparing\n",
      "19d043c86cbc: Preparing\n",
      "8823818c4748: Preparing\n",
      "0d64a93a303a: Waiting\n",
      "f41953166959: Waiting\n",
      "392a009de2b3: Waiting\n",
      "1db0da3b3d01: Waiting\n",
      "e46e9e8b1cbf: Waiting\n",
      "75b79e19929c: Waiting\n",
      "4775b2f378bb: Waiting\n",
      "883eafdbe580: Waiting\n",
      "19d043c86cbc: Waiting\n",
      "8823818c4748: Waiting\n",
      "d4618962ee78: Pushed\n",
      "9949025bc22c: Pushed\n",
      "f275626cba41: Pushed\n",
      "d43cd90ec4b4: Pushed\n",
      "1db0da3b3d01: Pushed\n",
      "f41953166959: Pushed\n",
      "e46e9e8b1cbf: Pushed\n",
      "75b79e19929c: Pushed\n",
      "4775b2f378bb: Pushed\n",
      "883eafdbe580: Pushed\n",
      "19d043c86cbc: Pushed\n",
      "8823818c4748: Pushed\n",
      "392a009de2b3: Pushed\n",
      "0d64a93a303a: Pushed\n",
      "ca9b91ed4222: Pushed\n",
      "latest: digest: sha256:479aed5769cb8f5ad3c8da53f610c518e62e756b1a404b73b9a3c3bfa4a4d25b size: 3460\n",
      "Removing login credentials for jkamllab6512356786.azurecr.io\n",
      "Docker push took 443.149112701416 seconds\n",
      "Not logged in to jkamllab6512356786.azurecr.io\n",
      "Docker logout(s) took 0.01778435707092285 seconds\n",
      "Removing image with name jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683\n",
      "Untagged: jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683:latest\n",
      "Untagged: jkamllab6512356786.azurecr.io/azureml/azureml_f279bc0a042728bf2096729c6942b683@sha256:479aed5769cb8f5ad3c8da53f610c518e62e756b1a404b73b9a3c3bfa4a4d25b\n",
      "Deleted: sha256:d1eba71d815935ca7f50e28216e7aed44c99c3c95c1a8e1283a86d39df863783\n",
      "Deleted: sha256:15eb5a7537e3beb12d0653d5fe8e1229a22ce9bf74755511a2a974e565093c9b\n",
      "Deleted: sha256:439b3b697a6eae4bc65e4002a343fde6e49da78728ee38504e7939fa5320067a\n",
      "Deleted: sha256:5e0f37fbd95d8db94f06b3723cf47af6c8893b9e215c6467540b90760f7b1346\n",
      "Deleted: sha256:9197a58ed82994a1be07f70dca6f708dd2be3b658abbc858d5b859e4929e0679\n",
      "Deleted: sha256:e44ce3d1db7ac5b4631b1a88eddd47f911c540aa5ba3b6a7e4128a5b0e8e48ce\n",
      "Deleted: sha256:8a3b33d7b3f90687828d1f44ce9fb23e92112262336f6b7aa0cebb1f284ac025\n",
      "Deleted: sha256:7b7c7f4c4887e86a80ab10faae20a2959b465133bca1bef486098aaf390e5880\n",
      "Deleted: sha256:9c368fada3b98b6b895ce8d666e018aba9282ab2870e9df805967f6a51666e80\n",
      "Deleted: sha256:20d5376204693a89da690d0435f764e7946a9112b91cce3238e081b16b9ace78\n",
      "Deleted: sha256:feb89b7a47acc167193d2bb01bbfc1592f3cfbf0016e436c5a4302f4dffcdda9\n",
      "Deleted: sha256:e4bc76cc2ec4e3e07475cd2a754c0628716cce2dd13d476b2ce3071ade8a7aa4\n",
      "Deleted: sha256:c1743d11c651904ea2794b9e75a1c83197fdffaef282a25c61148f3dcbaf9651\n",
      "Deleted: sha256:aa6555be3ae55ab18a41ab0f3dbf935400842f7f88a4b981f9f8e50a15f4915e\n",
      "Deleted: sha256:bdc2ee33f931f88bf9c2f43e4e1d7bfb47f6b28b05fc59590a1bcb359923141c\n",
      "Deleted: sha256:65211313874ed48d19d0b369b6a371db750a025e8ec59041e86884636b3ade58\n",
      "Deleted: sha256:7dfd465015cb7c64a7591f95e72440d757e64647d10b1df58736f75af37db55c\n",
      "Total task took 734.1636335849762 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Loading bottleneck features\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Traceback (most recent call last):\n",
      "  File \"azureml-setup/context_manager_injector.py\", line 114, in execute_with_context\n",
      "    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 263, in run_path\n",
      "    pkg_name=pkg_name, script_name=fname)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 96, in _run_module_code\n",
      "    mod_name, mod_spec, pkg_name, script_name)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"train.py\", line 104, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"train.py\", line 100, in main\n",
      "    train_evaluate(run)\n",
      "  File \"train.py\", line 46, in train_evaluate\n",
      "    with h5py.File(train_file_name, \"r\") as hfile:\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/h5py/_hl/files.py\", line 312, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/h5py/_hl/files.py\", line 142, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
      "OSError: Unable to open file (unable to open file: name = '/mnt/batch/tasks/shared/LS_root/jobs/batchaigpucls32898844e/azureml/aerial-train-fcnn_1542733666050/mounts/azureml_project_share/azureml/aerial-train-fcnn_1542733666050/workspacefilestore/bottleneck_features/aerial_bottleneck_resnet50.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.20094537734985352 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"azureml-setup/context_manager_injector.py\", line 204, in <module>\n",
      "    execute_with_context(cm_objects, options.invocation)\n",
      "  File \"azureml-setup/context_manager_injector.py\", line 114, in execute_with_context\n",
      "    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 263, in run_path\n",
      "    pkg_name=pkg_name, script_name=fname)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 96, in _run_module_code\n",
      "    mod_name, mod_spec, pkg_name, script_name)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"train.py\", line 104, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"train.py\", line 100, in main\n",
      "    train_evaluate(run)\n",
      "  File \"train.py\", line 46, in train_evaluate\n",
      "    with h5py.File(train_file_name, \"r\") as hfile:\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/h5py/_hl/files.py\", line 312, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
      "  File \"/azureml-envs/azureml_624b08cf195bb334786566e38b6f9b70/lib/python3.6/site-packages/h5py/_hl/files.py\", line 142, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
      "OSError: Unable to open file (unable to open file: name = '/mnt/batch/tasks/shared/LS_root/jobs/batchaigpucls32898844e/azureml/aerial-train-fcnn_1542733666050/mounts/azureml_project_share/azureml/aerial-train-fcnn_1542733666050/workspacefilestore/bottleneck_features/aerial_bottleneck_resnet50.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: aerial-train-fcnn_1542733666050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'aerial-train-fcnn_1542733666050',\n",
       " 'target': 'batchaigpucls',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2018-11-20T17:21:24.990693Z',\n",
       " 'endTimeUtc': '2018-11-20T17:23:42.80663Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'cde10f66-4381-4963-be8c-a7059f8f01c3'},\n",
       " 'runDefinition': {'Script': 'train.py',\n",
       "  'Arguments': ['--data_folder',\n",
       "   '$AZUREML_DATAREFERENCE_637b39c759914deaa658c2ade01cbaea',\n",
       "   '--training_file_name',\n",
       "   'aerial_bottleneck_resnet50.h5',\n",
       "   '--l1',\n",
       "   '0.001',\n",
       "   '--l2',\n",
       "   '0.001',\n",
       "   '--units',\n",
       "   '512',\n",
       "   '--epochs',\n",
       "   '10'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'batchaigpucls',\n",
       "  'DataReferences': {'637b39c759914deaa658c2ade01cbaea': {'DataStoreName': 'workspacefilestore',\n",
       "    'Mode': 'Download',\n",
       "    'PathOnDataStore': 'bottleneck_features',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'h5py',\n",
       "        'pillow',\n",
       "        'scikit-learn',\n",
       "        'tensorflow-gpu']}]},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.1.4',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'Location': None,\n",
       "   'RetainCluster': False,\n",
       "   'NodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://jkamllab3650394639.blob.core.windows.net/azureml/ExperimentRun/aerial-train-fcnn_1542733666050/azureml-logs/20_image_build_log.txt?sv=2017-04-17&sr=b&sig=eSU3B%2FkBTLTzrmh8Z1adMLkwVaZqUVHgovI%2FkNKvGf0%3D&st=2018-11-20T17%3A13%3A44Z&se=2018-11-21T01%3A23%3A44Z&sp=r',\n",
       "  'azureml-logs/60_control_log.txt': 'https://jkamllab3650394639.blob.core.windows.net/azureml/ExperimentRun/aerial-train-fcnn_1542733666050/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=DZRl8TmQd8FQH93PiiscE%2FI0Njwa3vjS2CeR8oUwrzs%3D&st=2018-11-20T17%3A13%3A44Z&se=2018-11-21T01%3A23%3A44Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://jkamllab3650394639.blob.core.windows.net/azureml/ExperimentRun/aerial-train-fcnn_1542733666050/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=3GEE9dfNgS%2Bd1kMxhR4ZI2Tbej11GCSgLdx6Ebe3kW8%3D&st=2018-11-20T17%3A13%3A44Z&se=2018-11-21T01%3A23%3A44Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://jkamllab3650394639.blob.core.windows.net/azureml/ExperimentRun/aerial-train-fcnn_1542733666050/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=YSSTm2R1kngKs7yO9Mvz4B8kQVfO8%2BOnOB7lA%2BmCIbo%3D&st=2018-11-20T17%3A13%3A44Z&se=2018-11-21T01%3A23%3A44Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://jkamllab3650394639.blob.core.windows.net/azureml/ExperimentRun/aerial-train-fcnn_1542733666050/azureml-logs/55_batchai_execution.txt?sv=2017-04-17&sr=b&sig=tpaDakbItHPIToAxw2fWXdQQH2J54YglSUb4DdDJj1I%3D&st=2018-11-20T17%3A13%3A44Z&se=2018-11-21T01%3A23%3A44Z&sp=r'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Hyperdrive\n",
    "\n",
    "As noted before, our network has 5 hyperparameters:\n",
    "\n",
    "- Number of units in the hidden layer\n",
    "- L1 and L2 regularization\n",
    "- mini-batch size, and\n",
    "- dropout ratio\n",
    "\n",
    "As we have limited time to complete the lab, we are going to limit a number of hyperparameter combinations to try. We will use a fixed batch-size and dropout ratio and focus on hidden layer units and L1 and L2 regularization.\n",
    "\n",
    "*Hyperdrive* supports many strategies for sampling the hyperparameter space. In this lab, we are going to use the simplest one - grid sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "ps = GridParameterSampling(\n",
    "    {\n",
    "        '--units': choice(256, 512),\n",
    "        '--l1': choice(0.001, 0.01, 0.05),\n",
    "        '--l2': choice(0.001, 0.01, 0.05)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **Estimator** object to configure the training job. Note how we pass the location of the bottleneck files to the estimator. The job will run on GPU VMs and as such we need to use the GPU version of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck_features').as_download(),\n",
    "    '--training_file_name': 'aerial_bottleneck_resnet50_brainwave.h5',\n",
    "    '--epochs': 50\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py','pillow', 'scikit-learn', 'tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=bai_compute_target,\n",
    "                entry_script=script_name,\n",
    "                pip_packages=pip_packages,\n",
    "                use_gpu=True,\n",
    "                node_count=1,\n",
    "                process_count_per_node=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperdrive* supports early termination policies to limit exploration of hyperparameter combinations that don't show promise of helping reach the target metric. This feature is especially useful when traversing large hyperparameter spaces. Since we are going to run a small number of jobs we will not apply early termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = NoTerminationPolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric as *validation_acc* that's recorded in our training runs. If you go back to visit the training script, you will notice that this value is being logged after every run. We also want to tell the service that we are looking to maximizing this value. We also set the number of total runs to 12, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps,\n",
    "                          policy=policy,\n",
    "                          primary_metric_name='validation_acc', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=12,\n",
    "                          max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job.\n",
    "\n",
    "The first run takes longer as the system has to prepare and deploy a docker image with training job runtime dependencies. As long as the dependencies don't change the following runs will be much faster.\n",
    "\n",
    "Here is what's happening whie you wait.\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs. During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically.\n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-train-fcnn</td><td>aerial-train-fcnn_1542743289813</td><td>hyperdrive</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-train-fcnn/runs/aerial-train-fcnn_1542743289813\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-train-fcnn,\n",
       "Id: aerial-train-fcnn_1542743289813,\n",
       "Type: hyperdrive,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {\"Compute target\": \"BAI\"}\n",
    "\n",
    "hdr = exp.submit(config=htc, tags=tags)\n",
    "hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4430ba493644c69ff70db5c9de39d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDrive(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.wait_for_completion(show_output=False) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register best model\n",
    "When all jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Validation Accuracy:', best_run_metrics['validation_acc'])\n",
    "print('\\n Units:',parameter_values[7])\n",
    "print('\\n L1:',parameter_values[9])\n",
    "print('\\n L2:',parameter_values[11])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "The last step in the training script wrote the file `aerial_fcnn_classifier.hd5` in the `outputs` directory. As noted before, `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. \n",
    "\n",
    "You can register the model so that it can be later queried, examined and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='aerial_classifier', \n",
    "                                model_path='outputs/aerial_fcnn_classifier.hd5')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "The model is now ready for deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "Before you move to the next step, delete the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bai_compute_target.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
