{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Feature Engineering\n",
    "In this lab we will develop and run a Python script that pre-processes our image set into a set of powerful features - sometimes referred to as bottleneck features.\n",
    "\n",
    "To create bottleneck features we will utilize a pre-trained Deep Learning network that was trained on a general computer vision domain. \n",
    "\n",
    "As explained by your instructor this approach is called Transfer Learning. Transfer Learning is a powerful Machine Learning technique that is based on an observation that the knowledge gained while solving one problem can be applied to a different (but related problem).\n",
    "\n",
    "In the context of an image classification task, a DNN trained on one visual domain can accelerate learing in another visual domain. Although, our pre-trained network does not know how to classify aerial land plot images, it knows enough about representing image concepts that if we use it to pre-process aerial images, the extracted image features can be used to effectively train a relatively simple classifier on a **limited number** of samples.\n",
    "\n",
    "The below diagram represents the architecture of our solution.\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tlcl.png)\n",
    "\n",
    "We will use **ResNet50** trained on **imagenet** dataset to extract features. We will occasionally refer to this component of the solution as a featurizer. The output of the featurizer is a vector of 2048 floating point numbers, each representing a feature extracted from an image. \n",
    "\n",
    "We will then use extracted features to train an scikit-learn classifier. (next lab).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML Experiment\n",
    "We will track runs of the feature engineering script in a dedicated Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-feature-engineering'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data pre-processing script\n",
    "\n",
    "The Python script processes an input image dataset into an output bottleneck feature set. The script expects the images to be organized in the below folder structure:\n",
    "```\n",
    "Barren/\n",
    "Cultivated/\n",
    "Developed/\n",
    "Forest/\n",
    "Herbaceous/\n",
    "Shrub/\n",
    "```\n",
    "\n",
    "The location of the input dataset and the location where to save the output dataset are passed to the script as command line parameters. The output dataset will be stored in a binary HDF5 data format used commonly in Machine Learning and High Performance Computing solutions.\n",
    "\n",
    "The script is designed to work with a large number of images. As such it does not load all input images to memory at once. Instead it utilizes custom Python generator class - `ImageGenerator` to feed the featurizer. The class yields batches of images - as Numpy arrays - preprocessed to the format required by **ResNet50**. \n",
    "\n",
    "We will not attempt to run the script on a full dataset in a local environment. It is very computationally intensive and unless you run it in an evironment equipped with a powerful GPU it would be very slow. \n",
    "\n",
    "However, we will demonstrate how to run the script locally using the same small development dataset we used in the previous lab. Running the script locally under the control of Azure ML can be very usefull during development and debugging.\n",
    "\n",
    "To process the full dataset we will execute the script on a remote Azure VM equipped with NVidia GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Jupyter `%%writefile` magic to write the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/extract.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# This is a generator that yields batches of preprocessed images\n",
    "class ImageGenerator(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, img_dir, preprocess_fn=None, batch_size=64):\n",
    "        \n",
    "        # Create the dictionary that maps class names into numeric labels   \n",
    "        label_map = {\n",
    "            \"Barren\": 0,\n",
    "            \"Cultivated\": 1,\n",
    "            \"Developed\": 2,\n",
    "            \"Forest\": 3,\n",
    "            \"Herbaceous\": 4,\n",
    "            \"Shrub\": 5}    \n",
    "        \n",
    "        # Create a list of all images in a root folder with associated numeric labels\n",
    "        folders = list(label_map.keys())\n",
    "        labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                              for folder in folders \n",
    "                              for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "        # Shuffle the list\n",
    "        random.shuffle(labeled_image_list)\n",
    "        \n",
    "        # Set image list and associated label list\n",
    "        self.image_list, self.label_list = zip(*labeled_image_list) \n",
    "        \n",
    "        # Set batch size\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "        # Set the pre-processing function passed as a parameter\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # Set number of batches\n",
    "        self.n_batches = len(self.image_list) // self.batch_size\n",
    "        if len(self.image_list) % self.batch_size > 0:\n",
    "            self.n_batches += 1\n",
    "            \n",
    "        # Set number of classes \n",
    "        self.num_classes = len(label_map)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Load a set of images passed as a parameter into a NumPy array\n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Return labels in one-hot encoding\n",
    "    def get_labels(self):\n",
    "        \n",
    "        #return to_categorical(np.asarray(self.label_list), self.num_classes)\n",
    "        return np.asarray(self.label_list)\n",
    "\n",
    "\n",
    "def create_bottleneck_features():\n",
    "    # Configure input directory\n",
    "    images_dir = FLAGS.input_data_dir\n",
    "\n",
    "    image_generator = ImageGenerator(images_dir, resnet50.preprocess_input)\n",
    "    \n",
    "    featurizer = resnet50.ResNet50(\n",
    "                weights = 'imagenet', \n",
    "                input_shape=(224,224,3), \n",
    "                include_top = False,\n",
    "                pooling = 'avg')\n",
    "    \n",
    "\n",
    "    # Generate bottleneck features\n",
    "    print(\"Generating bottleneck features\")\n",
    "    features = featurizer.predict_generator(image_generator, verbose=1)\n",
    "    labels = image_generator.get_labels()\n",
    "    \n",
    "    # Save the bottleneck features to HDF5 file\n",
    "    filename = FLAGS.file_name\n",
    "    output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    print(\"Saving bottleneck features to {}\".format(output_file))\n",
    "    print(\"   Features: \", features.shape)\n",
    "    print(\"   Labels: \", labels.shape)\n",
    "    with h5py.File(output_file, \"w\") as hfile:\n",
    "        features_dset = hfile.create_dataset('features', data=features)\n",
    "        labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "    \n",
    "    print(\"Done\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_string('input_data_dir', 'aerialtiny', \"Folder with training and validation images\")\n",
    "tf.app.flags.DEFINE_string('output_data_dir', 'bottleneck_features', \"A folder for saving bottleneck features\")\n",
    "tf.app.flags.DEFINE_string('file_name', 'aerial_bottleneck_resnet50.h5', \"Name of output training file\")\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    print(\"Starting\")\n",
    "    print(\"Reading images from:\", FLAGS.input_data_dir)\n",
    "    print(\"The output bottleneck file will be saved to:\", FLAGS.output_data_dir)\n",
    "\n",
    "    os.makedirs(FLAGS.output_data_dir, exist_ok=True)\n",
    "\n",
    "    create_bottleneck_features()\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script locally\n",
    "\n",
    "As noted in the introduction, we will first run the script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Run environment\n",
    "We will use a user-managed run, which means we assume that all the necessary packages are already available in the Python environment selected to run the script. In our case this is true, as we pre-installed all the dependencies during the lab setup. Alternatively, you can execute a local run in system-managed environment. In that case AML would build a new conda environment and execute the script in it.\n",
    "\n",
    "*Make sure to modify the **interpreter_path** property to point to your Python environment. On DSVM this path is `/anaconda/envs/py36/bin/python`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = '/anaconda/envs/py36/bin/python'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the script. \n",
    "Note that we need to supply an absolute path to the folder with training and validation images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='extract.py',\n",
    "    run_config=run_config,\n",
    "    arguments=['--input_data_dir', '/tmp/aerial-tiny',\n",
    "               '--output_data_dir', '/tmp/bottleneck_features',\n",
    "               '--file_name', 'aerial_bottleneck_resnet50_keras.h5']\n",
    "\n",
    "tags = {\"Compute target\": \"Local\", \"DNN\": \"ResNet50\"}\n",
    "run = exp.submit(src, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block to wait till run finishes and stream the output. Check CPU utilization on your workstation. On Linux run `htop` utility in a Jupyter terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs from the run have been pushed to AML Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottleneck files can be found in a local directory passed to the run as a command line parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls /tmp/bottleneck_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script on a remote GPU VM\n",
    "\n",
    "As you can see, even on a really small dataset the processing is very slow. In the next step, you will run the script on a full dataset using a remote GPU equipped VM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure DSVM as a compute target\n",
    "\n",
    "We will use *Standard_NC6* VM equipped with Tesla K80 GPU as a compute target. If the VM is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import DsvmCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'gpudsvm'\n",
    "compute_target_type = 'Standard_NC6'\n",
    "\n",
    "try:\n",
    "    dsvm_compute = DsvmCompute(workspace=ws, name=compute_target_name)\n",
    "    print('Found existing DSVM:', dsvm_compute.name)\n",
    "except ComputeTargetException:\n",
    "    dsvm_config = DsvmCompute.provisioning_configuration(vm_size=compute_target_type)\n",
    "    dsvm_compute = DsvmCompute.create(ws, name=compute_target_name, provisioning_configuration=dsvm_config)\n",
    "    dsvm_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Datastores \n",
    "The dataset we will use for training has been uploaded to a public Azure blob storage container. We will register this container as an AML Datastore within our workspace. Before the data prep script runs, the datastore's content - training images - will be copied to the local storage on DSVM.\n",
    "\n",
    "After the script completes, its output - the bottleneck features file - will be uploaded by AML to the workspace's default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "images_account = 'azureailabs'\n",
    "images_container = 'aerial-med'\n",
    "datastore_name = 'input_images'\n",
    "\n",
    "# Check if the datastore exists. If not create a new one\n",
    "try:\n",
    "    input_ds = Datastore.get(ws, datastore_name)\n",
    "    print('Found existing datastore for input images:', input_ds.name)\n",
    "except:\n",
    "    input_ds = Datastore.register_azure_blob_container(workspace=ws, datastore_name=datastore_name,\n",
    "                                            container_name=images_container,\n",
    "                                            account_name=images_account)\n",
    "    print('Creating new datastore for input images')\n",
    "\n",
    " \n",
    "   \n",
    "print(input_ds.name, input_ds.datastore_type, input_ds.account_name, input_ds.container_name)\n",
    "\n",
    "output_ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for output: \")\n",
    "print(output_ds.name, output_ds.datastore_type, output_ds.account_name, output_ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and monitor a remote run\n",
    "\n",
    "We will run a script in a new Conda environment that will be created automatically by AML and configured with the \n",
    "specified dependencies.\n",
    "\n",
    "The first run takes longer. The subsequent runs, as long as the script dependencies don't change, are much faster.\n",
    "\n",
    "You can check the progress of a running job in multiple ways: Azure Portal, AML Jupyter Widgets, log files streaming. We will use AML Jupyter Widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_folder = 'script'\n",
    "script_name = 'extract.py'\n",
    "output_dir = 'bottleneck_features'\n",
    "input_dir = 'aerial'\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to DSVM\n",
    "conda_run_config.target = dsvm_compute.name\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "conda_packages = ['scikit-image', 'h5py', 'tensorflow-gpu']\n",
    "conda_run_config.environment.python.conda_dependencies = \\\n",
    "    CondaDependencies.create(conda_packages=conda_packages)\n",
    "    \n",
    "\n",
    "# configure data references\n",
    "input_dr = DataReferenceConfiguration(datastore_name=input_ds.name, \n",
    "                   path_on_compute=input_dir,                   \n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n",
    "\n",
    "output_dr = DataReferenceConfiguration(datastore_name=output_ds.name, \n",
    "                   path_on_datastore=output_dir, \n",
    "                   path_on_compute=output_dir,\n",
    "                   mode='upload', # upload files from the compute to datastore\n",
    "                   overwrite=True)\n",
    "\n",
    "conda_run_config.data_references = {input_ds.name: input_dr, output_ds.name: output_dr}\n",
    "    \n",
    "\n",
    "# Specify command line arguments\n",
    "arguments = ['--input_data_dir', str(input_ds.as_download()),\n",
    "             '--output_data_dir', output_dir,\n",
    "             '--file_name', 'aerial_bottleneck_resnet50_keras.h5']\n",
    "\n",
    "\n",
    "# Configure the script \n",
    "src = ScriptRunConfig(source_directory=script_folder, \n",
    "                      script=script_name, \n",
    "                      run_config=conda_run_config, \n",
    "                      arguments=arguments \n",
    "                     ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the run and start RunDetails widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "\n",
    "tags = {\"Compute target\": \"DSVM\", \"DNN\": \"ResNet50\"}\n",
    "run = exp.submit(src)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block to wait till the run finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the run, AML copied the output bottleneck files to the default datastore. You can verify it using Azure Portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Before you move to the next step, you can delete the GPU VM. We will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvm_compute.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "The run has completed. You are ready to move to the next part of the lab in which you are going to train a multinomial classification model using the bottleneck features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
